{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "base_path = Path(\"../logs/exp_generalization_datasets/results_SAT1Base.json\")\n",
    "gru_path = Path(\"../logs/exp_generalization_datasets/results_SAT1GRU.json\")\n",
    "transformer_path = Path(\"../logs/exp_generalization_datasets/results_TransformerModel.json\")\n",
    "\n",
    "path_to_model = {str(base_path): 'CNN', str(gru_path): 'GRU', str(transformer_path): 'Transformer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "classes = ['pre-attentive', 'encoding', 'confirmation', 'decision', 'response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Per class accuracy does not exist, only precision and f1-score\n",
    "def get_metric(path, to, metric):\n",
    "    scores = defaultdict(lambda: list())\n",
    "    data = json.load(path.open())\n",
    "    data_keys = {'sat2': '0', 'sat1': '1', 'ar': '2'}\n",
    "    for fold in data[data_keys[to]]:\n",
    "        for label in ['0', '1', '2', '3', '4']:\n",
    "            if metric == 'precision':\n",
    "                metric_value = fold[label][metric]\n",
    "            elif metric == 'f1-score':\n",
    "                metric_value = fold[label][metric]\n",
    "            scores[label].append(metric_value)\n",
    "    return scores\n",
    "\n",
    "def plot_performance_per_class(to='sat2', metric='precision'):\n",
    "    avgs = defaultdict(lambda: list())\n",
    "    for path in [base_path, gru_path, transformer_path]:\n",
    "        scores = get_metric(path, to=to, metric=metric)\n",
    "        for key, val in scores.items():\n",
    "            mean = sum(val)/len(val)\n",
    "            avgs[path_to_model[str(path)]].append(mean)\n",
    "\n",
    "    df = pd.DataFrame(avgs).T\n",
    "\n",
    "    df.columns = classes\n",
    "    # df.index = [path.stem for path in df.index]\n",
    "    df = df.reset_index().melt(id_vars='index', var_name='Class', value_name='Performance')\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    sns.barplot(data=df, x='Class', y='Performance', hue='index')\n",
    "    plt.title(f'Performance Per Class for Each Model (Trained on SAT2, tested on {to.upper()})')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend(title='Model', loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "metric = 'f1-score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plot_performance_per_class(to='sat2', metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plot_performance_per_class(to='sat1', metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plot_performance_per_class(to='ar', metric=metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
