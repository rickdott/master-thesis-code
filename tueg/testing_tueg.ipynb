{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))\n",
    "import pyedflib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_path = str(DATA_PATH / \"tueg/aaaaawey_s001_t001.edf\")\n",
    "f = pyedflib.EdfReader(edf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "['EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF', 'EEG A1-REF', 'EEG A2-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF', 'EEG ROC-REF', 'EEG LOC-REF', 'EEG EKG1-REF', 'EMG-REF', 'EEG T1-REF', 'EEG T2-REF', 'PHOTIC-REF', 'IBI', 'BURSTS', 'SUPPR']\n"
     ]
    }
   ],
   "source": [
    "# Check num of channels\n",
    "print(f.signals_in_file)\n",
    "# Check labels of channels\n",
    "print(f.getSignalLabels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([250., 250., 250., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "       250., 250., 250., 250., 250., 250., 250., 250., 250., 250., 250.,\n",
       "       250., 250., 250., 250., 250., 250.,   1.,   1.,   1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequencies of channels\n",
    "f.getSampleFrequencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([327750, 327750, 327750, 327750, 327750, 327750, 327750, 327750,\n",
       "       327750, 327750, 327750, 327750, 327750, 327750, 327750, 327750,\n",
       "       327750, 327750, 327750, 327750, 327750, 327750, 327750, 327750,\n",
       "       327750, 327750, 327750, 327750,   1311,   1311,   1311])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of samples for each channel\n",
    "f.getNSamples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = f.signals_in_file\n",
    "length = 500\n",
    "\n",
    "signals = np.zeros((n, length))\n",
    "for i in np.arange(n):\n",
    "    signals[i, :] = f.readSignal(i, n=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "CHUNK_SIZE = 150\n",
    "FILE_SIZE = 1000\n",
    "PATH_BASE = Path(\"../../data/tueg_split\")\n",
    "def process_split_chunk(chunk):\n",
    "    n_data = len(chunk)\n",
    "    proc = multiprocessing.current_process().pid\n",
    "    \n",
    "    for iter_idx, (idx, row) in enumerate(chunk.iterrows()):\n",
    "        # List to keep (N, 100) samples where N = num_channels\n",
    "        if row.processed or not row.match:\n",
    "            continue\n",
    "        # If frequency does not match, do not do anything with file (for now?)\n",
    "        if row.frequency != 256 and row.frequency != 250:\n",
    "            chunk.loc[idx, 'processed'] = True\n",
    "            continue\n",
    "        edf = pyedflib.EdfReader(row.path)\n",
    "        ch_list = ast.literal_eval(row.channels)\n",
    "        n_ch = len(electrode_mapping)\n",
    "        n_buf = edf.getNSamples()[0]\n",
    "        # Create big signals ndarray\n",
    "        signals = np.zeros((n_ch, n_buf), dtype=np.float32)\n",
    "        electrodes = list(electrode_mapping.keys())\n",
    "        for ch_idx, ch in enumerate(ch_list):\n",
    "            ch_name = ch.split('-')[0]\n",
    "            # Save index in edf file\n",
    "            if ch_name in electrode_mapping:\n",
    "                signals[electrodes.index(ch_name), :] = edf.readSignal(ch_idx, n=n_buf)\n",
    "        edf.close()\n",
    "        n_chunks = n_buf // CHUNK_SIZE\n",
    "\n",
    "        # If LE, average reference\n",
    "        if 'tcp_le' in row.path:\n",
    "            ch_mean = np.mean(signals, axis=0)\n",
    "            signals = signals - ch_mean\n",
    "        \n",
    "        # Truncate to divide by CHUNK_SIZE\n",
    "        signals = signals[:, :n_chunks * CHUNK_SIZE]\n",
    "\n",
    "        # z_score = (signals - signals.mean()) / signals.std()\n",
    "        # plt.plot(signals.mean(axis=0))\n",
    "        # Split time dimensions into chunks of size CHUNK_SIZE\n",
    "        signals = signals.reshape(-1, n_ch, CHUNK_SIZE)\n",
    "\n",
    "        # Robust z-score the data\n",
    "        median = np.median(signals)\n",
    "        mad = np.median(np.abs(signals - median), keepdims=True)\n",
    "        mad[mad == 0] = 1e-6\n",
    "        z_scored_signals = (signals - median) / mad\n",
    "\n",
    "        # Split filtered_signals up into chunks of 1000 and save this and remainder to disk\n",
    "        num_chunks = (z_scored_signals.shape[0] + FILE_SIZE - 1) // FILE_SIZE\n",
    "        for i in range(num_chunks):\n",
    "            start_idx = i * FILE_SIZE\n",
    "            end_idx = min((i + 1) * FILE_SIZE, z_scored_signals.shape[0])\n",
    "            data_chunk = z_scored_signals[start_idx:end_idx]\n",
    "            filename = PATH_BASE / f\"{row.path.split('edf/')[1].replace('/', '_')[:-4]}_chunk_{i}.npy\"\n",
    "            np.save(filename, data_chunk)\n",
    "        \n",
    "        if (iter_idx + 1) % 10 == 0:\n",
    "            print(f'Worker {proc}: {iter_idx + 1}/{n_data}, Finished processing {row.path}')\n",
    "        chunk.loc[idx, 'processed'] = True\n",
    "    \n",
    "    return chunk\n",
    "\n",
    "# Deprecated\n",
    "        # Remove entries with values that fall outside the 5th and 95th percentile bound\n",
    "        # First z-score, then remove \n",
    "        # z_score = (signals - signals.mean()) / signals.std()\n",
    "        # print(f'Mean: {signals.mean()}, std: {signals.std()}')\n",
    "        # mask = np.abs(z_score) < 3\n",
    "        # valid_entries_mask = np.all(mask, axis=(1, 2))\n",
    "        # plt.scatter(x=np.linspace(0, n_chunks * CHUNK_SIZE, n_chunks), y=(valid_entries_mask - 0.5) * 200, c=valid_entries_mask)\n",
    "        # plt.xlim(0, 10000)\n",
    "        # plt.ylim(-105, 105)\n",
    "        # plt.show()\n",
    "        # lower_bound = np.percentile(signals, 1)\n",
    "        # upper_bound = np.percentile(signals, 99)\n",
    "        # mask = (signals >= lower_bound) & (signals <= upper_bound)\n",
    "        # valid_entries_mask = np.all(mask, axis=(1, 2))\n",
    "\n",
    "        # filtered_signals = signals[valid_entries_mask]\n",
    "\n",
    "        # Reorder channels dim\n",
    "        # ch_indices = list(electrode_idx_mapping.values())\n",
    "        # filtered_signals = filtered_signals[ch_indices]\n",
    "\n",
    "        # Normalize over valid signals to [-1, 1], loses amplitude information compared to rest of data\n",
    "        # min_val = filtered_signals.min()\n",
    "        # max_val = filtered_signals.max()\n",
    "        # filtered_signals = 2 * (filtered_signals - min_val) / (max_val - min_val) - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
