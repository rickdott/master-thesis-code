{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libcudart.so.12: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mselective_scan_cuda\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: libcudart.so.12: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import selective_scan_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.8'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libcudart.so.12: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhmpai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhmpai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_data_on_participants, split_participants\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhmpai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train, validate, calculate_class_weights, train_and_test, k_fold_cross_validate, test, calculate_global_class_weights, EarlyStopper\n",
      "File \u001b[0;32m/workspace/hmp-ai/src/hmpai/pytorch/models.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhmpai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEVICE\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba_ssm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mamba2, Mamba\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLearnablePositionalEncoding\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, d_model, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.2.4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselective_scan_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m selective_scan_fn, mamba_inner_fn\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmamba_simple\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mamba\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmamba2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mamba2\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/selective_scan_interface.py:18\u001b[0m\n\u001b[1;32m     14\u001b[0m     causal_conv1d_cuda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_norm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _layer_norm_fwd\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mselective_scan_cuda\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSelectiveScanFn\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mFunction):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, u, delta, A, B, C, D\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, delta_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, delta_softplus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     25\u001b[0m                 return_last_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[0;31mImportError\u001b[0m: libcudart.so.12: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from hmpai.pytorch.models import *\n",
    "from hmpai.training import split_data_on_participants, split_participants\n",
    "from hmpai.pytorch.training import train, validate, calculate_class_weights, train_and_test, k_fold_cross_validate, test, calculate_global_class_weights, EarlyStopper\n",
    "from hmpai.pytorch.utilities import DEVICE, set_global_seed, get_summary_str, save_model, load_model\n",
    "from hmpai.pytorch.generators import SAT1Dataset, MultiXArrayDataset, MultiXArrayProbaDataset\n",
    "from hmpai.data import SAT1_STAGES_ACCURACY, SAT_CLASSES_ACCURACY\n",
    "from hmpai.visualization import plot_confusion_matrix\n",
    "from hmpai.pytorch.normalization import *\n",
    "from torchinfo import summary\n",
    "from hmpai.utilities import print_results, CHANNELS_2D, AR_SAT1_CHANNELS\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from hmpai.pytorch.transforms import *\n",
    "from hmpai.pytorch.mamba import *\n",
    "from hmpai.behaviour.sat2 import read_behavioural_info\n",
    "from hmpai.visualization import display_trial\n",
    "from hmpai.behaviour.sat2 import SAT2_SPLITS\n",
    "# from braindecode.models.eegconformer import EEGConformer\n",
    "from mne.io import read_info\n",
    "import os\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(42)\n",
    "\n",
    "data_paths = [DATA_PATH / \"sat2/stage_data_proba_250hz.nc\"]\n",
    "\n",
    "# train_percentage=100 makes test and val 100 as well\n",
    "# splits = split_participants(data_paths, train_percentage=60)\n",
    "splits = SAT2_SPLITS\n",
    "labels = SAT_CLASSES_ACCURACY\n",
    "info_to_keep = ['event_name', 'participant', 'epochs', 'rt']\n",
    "whole_epoch = True\n",
    "# subset_cond = 'accuracy'\n",
    "subset_cond = None\n",
    "add_negative = True\n",
    "skip_samples = 0 # 62\n",
    "cut_samples = 0 # 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_fn = norm_mad_zscore\n",
    "train_data = MultiXArrayProbaDataset(\n",
    "    data_paths,\n",
    "    participants_to_keep=splits[0],\n",
    "    normalization_fn=norm_fn,\n",
    "    whole_epoch=whole_epoch,\n",
    "    labels=labels,\n",
    "    info_to_keep=info_to_keep,\n",
    "    subset_cond=subset_cond,\n",
    "    add_negative=add_negative,\n",
    "    # Replace with startjittertransform\n",
    "    # transform=Compose([FixedLengthCropTransform(), ReverseTimeTransform()]),\n",
    "    # transform=Compose([StartJitterTransform(62, 1.0), EndJitterTransform(63, 1.0), ReverseTimeTransform(0.1), ConcatenateTransform(0.1)]),\n",
    "    transform=Compose([StartJitterTransform(62, 1.0), EndJitterTransform(63, 1.0)]),\n",
    "    # transform=Compose([StartJitterQuadraticTransform(62, 1.0), EndJitterQuadraticTransform(63, 1.0)]),\n",
    "    # transform=Compose([ReverseTimeTransform(0.5), ConcatenateTransform(0.5)]),\n",
    "    # transform=Compose([ReverseTimeTransform(0.5), TimeDropoutTransform(), ConcatenateTransform(0.5)]),\n",
    "    # transform=Compose([StartJitterTransform(62), FixedLengthCropTransform()]),\n",
    "    skip_samples=skip_samples,\n",
    "    cut_samples=cut_samples,\n",
    ")\n",
    "norm_vars = get_norm_vars_from_global_statistics(train_data.statistics, norm_fn)\n",
    "class_weights = train_data.statistics[\"class_weights\"]\n",
    "test_data = MultiXArrayProbaDataset(\n",
    "    data_paths,\n",
    "    participants_to_keep=splits[1],\n",
    "    normalization_fn=norm_fn,\n",
    "    norm_vars=norm_vars,\n",
    "    whole_epoch=whole_epoch,\n",
    "    labels=labels,\n",
    "    info_to_keep=info_to_keep,\n",
    "    subset_cond=subset_cond,\n",
    "    add_negative=add_negative,\n",
    "    skip_samples=skip_samples,\n",
    "    cut_samples=cut_samples,\n",
    ")\n",
    "val_data = MultiXArrayProbaDataset(\n",
    "    data_paths,\n",
    "    participants_to_keep=splits[2],\n",
    "    normalization_fn=norm_fn,\n",
    "    norm_vars=norm_vars,\n",
    "    whole_epoch=whole_epoch,\n",
    "    labels=labels,\n",
    "    info_to_keep=info_to_keep,\n",
    "    subset_cond=subset_cond,\n",
    "    add_negative=add_negative,\n",
    "    skip_samples=skip_samples,\n",
    "    cut_samples=cut_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TestMamba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTestMamba\u001b[49m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;241m5\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m train_and_test(\n\u001b[1;32m      3\u001b[0m     model,\n\u001b[1;32m      4\u001b[0m     train_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TestMamba' is not defined"
     ]
    }
   ],
   "source": [
    "model = TestMamba(64, 128, 64, len(labels), 5, False)\n",
    "train_and_test(\n",
    "    model,\n",
    "    train_data,\n",
    "    test_data,\n",
    "    val_data,\n",
    "    logs_path=Path(\"../logs/\"),\n",
    "    workers=8,\n",
    "    batch_size=32,\n",
    "    labels=labels,\n",
    "    lr=0.0001,\n",
    "    # lr=0.0005,\n",
    "    # label_smoothing=0.1,\n",
    "    # weight_decay=0.0001,\n",
    "    do_spectral_decoupling=False,\n",
    "    use_class_weights=False,\n",
    "    class_weights=class_weights,\n",
    "    whole_epoch=True,\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in behavioural data\n",
    "behaviour_sat2 = read_behavioural_info(DATA_PATH / \"sat2/behavioural/df_full.csv\")\n",
    "test_loader_sat2 = DataLoader(\n",
    "    test_data, batch_size=128, shuffle=True, num_workers=8, pin_memory=True\n",
    ")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in torch.randint(len(test_data), (10,)):\n",
    "    print(i)\n",
    "    display_trial(model, test_data, behaviour_sat2, i, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19b53231533462f9167fd9f7ca50272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80644970bd5c4b2d9d519ee3530bc989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4047d1aeff41a4aa9b57359b211ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47558fde782b4bc0b7d6869425ea6755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e00aec2d89c43c69a217fb75e4305a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6179d3965014aa3abe8f8c7395a2bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b021d9b183f64ec8b913de70028c015e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2c0de143d84a8f9185913b668682cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03255bf2e49495eb4e3ed99b78c6a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeba51d579b945dea934d3e8baddd5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9aba9565d5844d0b5d38125c4495f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5d55c57ef541028a1baeef4e939f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49636c53452457788d7e64c42456922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b41108067d64c6a91d0d80adc509dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m base_mamba()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 2 workers, ~18 b/s\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 4 workers, ~35 b/s\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 8 workers, ~48 b/s\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 12 workers, ~48 b/s\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain_and_test\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogs_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../logs/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# lr=0.0005,\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# label_smoothing=0.1,\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# weight_decay=0.0001,\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_spectral_decoupling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_class_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhole_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/hmp-ai/src/hmpai/pytorch/training.py:273\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m(model, train_set, test_set, val_set, batch_size, epochs, workers, logs_path, additional_info, additional_name, use_class_weights, class_weights, label_smoothing, weight_decay, lr, do_spectral_decoupling, labels, seed, pretrain_fn, whole_epoch, probabilistic_labels, do_test_shuffled)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# Train on batches in train_loader\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrain_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     batch_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_spectral_decoupling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_spectral_decoupling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhole_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhole_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     batch_losses \u001b[38;5;241m=\u001b[39m pretrain_train(\n\u001b[1;32m    284\u001b[0m         model, train_loader, opt, loss, pretrain_fn, progress\u001b[38;5;241m=\u001b[39mtepoch\n\u001b[1;32m    285\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/hmp-ai/src/hmpai/pytorch/training.py:498\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, loss_fn, progress, do_spectral_decoupling, whole_epoch)\u001b[0m\n\u001b[1;32m    496\u001b[0m loss \u001b[38;5;241m=\u001b[39m kldiv_loss(predictions\u001b[38;5;241m.\u001b[39mclone(), labels\u001b[38;5;241m.\u001b[39mclone())\n\u001b[1;32m    497\u001b[0m c_mse \u001b[38;5;241m=\u001b[39m cum_mse(predictions\u001b[38;5;241m.\u001b[39mclone(), labels\u001b[38;5;241m.\u001b[39mclone())\n\u001b[0;32m--> 498\u001b[0m c_mses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mc_mse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    499\u001b[0m emd_val \u001b[38;5;241m=\u001b[39m emd_loss(predictions\u001b[38;5;241m.\u001b[39mclone(), labels\u001b[38;5;241m.\u001b[39mclone())\n\u001b[1;32m    500\u001b[0m emd_vals\u001b[38;5;241m.\u001b[39mappend(emd_val)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = base_mamba()\n",
    "# 2 workers, ~18 b/s\n",
    "# 4 workers, ~35 b/s\n",
    "# 8 workers, ~48 b/s\n",
    "# 12 workers, ~48 b/s\n",
    "train_and_test(\n",
    "    model,\n",
    "    train_data,\n",
    "    test_data,\n",
    "    val_data,\n",
    "    logs_path=Path(\"../logs/\"),\n",
    "    workers=8,\n",
    "    batch_size=64,\n",
    "    labels=labels,\n",
    "    lr=0.0001,\n",
    "    # lr=0.0005,\n",
    "    # label_smoothing=0.1,\n",
    "    # weight_decay=0.0001,\n",
    "    do_spectral_decoupling=False,\n",
    "    use_class_weights=False,\n",
    "    class_weights=class_weights,\n",
    "    whole_epoch=True,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1031.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MambaModel                               [1, 638, 5]               4,883\n",
       "├─Linear: 1-1                            [1, 638, 128]             2,560\n",
       "├─Sequential: 1-2                        [1, 256, 638]             --\n",
       "│    └─Conv1d: 2-1                       [1, 256, 638]             1,638,656\n",
       "│    └─ReLU: 2-2                         [1, 256, 638]             --\n",
       "├─Sequential: 1-3                        [1, 638, 256]             --\n",
       "│    └─MambaBlock: 2-3                   [1, 638, 256]             --\n",
       "│    │    └─Mamba: 3-1                   [1, 638, 256]             437,760\n",
       "│    │    └─LayerNorm: 3-2               [1, 638, 256]             512\n",
       "│    │    └─Dropout: 3-3                 [1, 638, 256]             --\n",
       "│    └─MambaBlock: 2-4                   [1, 638, 256]             --\n",
       "│    │    └─Mamba: 3-4                   [1, 638, 256]             437,760\n",
       "│    │    └─LayerNorm: 3-5               [1, 638, 256]             512\n",
       "│    │    └─Dropout: 3-6                 [1, 638, 256]             --\n",
       "│    └─MambaBlock: 2-5                   [1, 638, 256]             --\n",
       "│    │    └─Mamba: 3-7                   [1, 638, 256]             437,760\n",
       "│    │    └─LayerNorm: 3-8               [1, 638, 256]             512\n",
       "│    │    └─Dropout: 3-9                 [1, 638, 256]             --\n",
       "│    └─MambaBlock: 2-6                   [1, 638, 256]             --\n",
       "│    │    └─Mamba: 3-10                  [1, 638, 256]             437,760\n",
       "│    │    └─LayerNorm: 3-11              [1, 638, 256]             512\n",
       "│    │    └─Dropout: 3-12                [1, 638, 256]             --\n",
       "│    └─MambaBlock: 2-7                   [1, 638, 256]             --\n",
       "│    │    └─Mamba: 3-13                  [1, 638, 256]             437,760\n",
       "│    │    └─LayerNorm: 3-14              [1, 638, 256]             512\n",
       "│    │    └─Dropout: 3-15                [1, 638, 256]             --\n",
       "├─Linear: 1-4                            [1, 638, 5]               1,285\n",
       "==========================================================================================\n",
       "Total params: 3,838,744\n",
       "Trainable params: 3,838,744\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.13\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 29.40\n",
       "Params size (MB): 9.74\n",
       "Estimated Total Size (MB): 39.20\n",
       "=========================================================================================="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = MambaModel(128, 19, len(labels), \n",
    "                   5, global_pool=False, dropout=0.1)\n",
    "\n",
    "input_shape = (1, 638, 19)\n",
    "summary(model, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAT1GRU(64, 5)\n",
    "\n",
    "train_and_test(\n",
    "    model,\n",
    "    train_data,\n",
    "    test_data,\n",
    "    val_data,\n",
    "    logs_path=Path(\"../logs/\"),\n",
    "    workers=0,\n",
    "    batch_size=128,\n",
    "    labels=SAT_CLASSES_ACCURACY,\n",
    "    label_smoothing=0.0001,\n",
    "    weight_decay=0.01,\n",
    "    lr=0.001,\n",
    "    do_spectral_decoupling=False,\n",
    "    use_class_weights=True,\n",
    "    class_weights=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_path = Path(\"../models/gru100/checkpoint.pt\")\n",
    "checkpoint = load_model(chk_path)\n",
    "\n",
    "model_kwargs = {\n",
    "    \"n_channels\": len(dataset_sat1.channels),\n",
    "    \"n_samples\": len(dataset_sat1.samples),\n",
    "    \"n_classes\": len(dataset_sat1.labels),\n",
    "}\n",
    "model = SAT1GRU(**model_kwargs)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_data, 128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "results, pred, true = test(model, test_loader, None)\n",
    "pred = pred.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    train_dataset_sat1, 128, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "results, pred, true = test(model, test_loader, None)\n",
    "pred = pred.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(true, pred, SAT1_STAGES_ACCURACY[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
