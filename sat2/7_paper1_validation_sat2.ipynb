{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from hmpai.pytorch.models import *\n",
    "from hmpai.training import split_data_on_participants, split_participants\n",
    "from hmpai.pytorch.training import train, validate, calculate_class_weights, train_and_test, k_fold_cross_validate, test, calculate_global_class_weights\n",
    "from hmpai.pytorch.utilities import DEVICE, set_global_seed, get_summary_str, save_model, load_model\n",
    "from hmpai.pytorch.generators import SAT1Dataset, MultiXArrayDataset, MultiXArrayProbaDataset\n",
    "from hmpai.data import SAT1_STAGES_ACCURACY, SAT_CLASSES_ACCURACY\n",
    "from hmpai.visualization import plot_confusion_matrix\n",
    "from hmpai.pytorch.normalization import *\n",
    "from torchinfo import summary\n",
    "from hmpai.utilities import print_results, CHANNELS_2D, AR_SAT1_CHANNELS\n",
    "from torch.utils.data import DataLoader\n",
    "# from braindecode.models.eegconformer import EEGConformer\n",
    "from mne.io import read_info\n",
    "import os\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))\n",
    "from hmpai.visualization import plot_predictions_on_epoch, predict_with_auc, show_lmer, set_seaborn_style\n",
    "import pandas as pd\n",
    "from hmpai.behaviour.sat2 import read_behavioural_info\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each combination of dimensions:\n",
    "\tpredict on test and validation data\n",
    "\tpredict on test and validation data, but shuffle the data of each sample (ensure order is the same)\n",
    "\tfor model_pred, model_pred_shuffled in zip(model_preds, model_preds_shuffled)\n",
    "\t\tcorr_model = corr(model_pred, hmp_probas)\n",
    "\t\tcorr_null = corr(model_pred_shuffled, hmp_probas)\n",
    "\t\tdifference = corr_model - corr_null\n",
    "\t\tsave difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(42)\n",
    "data_path_1 = DATA_PATH / \"sat2/stage_data_proba_250hz_part1.nc\"\n",
    "data_path_2 = DATA_PATH / \"sat2/stage_data_proba_250hz_part2.nc\"\n",
    "data_paths = [data_path_1, data_path_2]\n",
    "# train_percentage=100 makes test and val 100 as well\n",
    "splits = split_participants(data_paths, train_percentage=60)\n",
    "labels = SAT_CLASSES_ACCURACY\n",
    "whole_epoch = True\n",
    "info_to_keep = ['rt', 'participant', 'epochs']\n",
    "subset_cond = None # 'speed'|'accuracy'|None\n",
    "skip_samples = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_fn = norm_mad_zscore\n",
    "# Shortcut so they dont have to be recalculated each time\n",
    "statistics = {\n",
    "    \"global_min\": -0.00014557216,\n",
    "    \"global_max\": 0.00014740844,\n",
    "    \"global_mean\": -2.277374212336032e-18,\n",
    "    \"global_std\": 3.3968840765876904e-06,\n",
    "    \"global_median\": 3.4879516e-11,\n",
    "    \"mad_score\": 3.2237037e-06,\n",
    "    \"class_weights\": Tensor([0.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "}\n",
    "\n",
    "norm_vars = get_norm_vars_from_global_statistics(statistics, norm_fn)\n",
    "\n",
    "# train_data = MultiXArrayProbaDataset(\n",
    "#     data_paths,\n",
    "#     participants_to_keep=splits[0],\n",
    "#     normalization_fn=norm_fn,\n",
    "#     whole_epoch=whole_epoch,\n",
    "#     labels=labels,\n",
    "#     info_to_keep=info_to_keep,\n",
    "#     subset_cond=subset_cond,\n",
    "#     statistics=statistics,\n",
    "# )\n",
    "# class_weights = train_data.statistics[\"class_weights\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def pearson_corrcoef(t1: torch.Tensor, t2: torch.Tensor):\n",
    "    t1 = t1.flatten().to(DEVICE)\n",
    "    t2 = t2.flatten().to(DEVICE)\n",
    "\n",
    "    mean1 = t1.mean()\n",
    "    mean2 = t2.mean()\n",
    "\n",
    "    dev1 = t1 - mean1\n",
    "    dev2 = t2 - mean2\n",
    "\n",
    "    covariance = torch.sum(dev1 * dev2)\n",
    "\n",
    "    std1 = torch.sqrt(torch.sum(dev1 ** 2))\n",
    "    std2 = torch.sqrt(torch.sum(dev2 ** 2))\n",
    "\n",
    "    # Case where all values in t1 or t2 are the same (no std defined)\n",
    "    if std1 == 0 or std2 == 0:\n",
    "        return torch.nan\n",
    "\n",
    "    correlation = covariance / (std1 * std2)\n",
    "\n",
    "    return correlation.item()\n",
    "\n",
    "def spearman_corrcoef(t1: torch.Tensor, t2: torch.Tensor):\n",
    "    # Assuming that t2 is hmp\n",
    "    t1 = t1.flatten().to('cpu')\n",
    "    t2 = t2.flatten().to('cpu')\n",
    "\n",
    "    non_zero = t2 != 0\n",
    "\n",
    "    spearman_corr = spearmanr(t1[non_zero], t2[non_zero])\n",
    "\n",
    "    return spearman_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now testing model: crop_jitter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744785e60e464878b1f1890a2fbf33ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (128) must match the existing size (10) at non-singleton dimension 0.  Target sizes: [128, 572, 5].  Tensor sizes: [10, 572, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 116\u001b[0m\n\u001b[1;32m    114\u001b[0m     shuffled_pred \u001b[38;5;241m=\u001b[39m model(batch_data\u001b[38;5;241m.\u001b[39mto(DEVICE))\n\u001b[1;32m    115\u001b[0m     shuffled_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)(shuffled_pred)\n\u001b[0;32m--> 116\u001b[0m     shuffled_preds[:, i, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m shuffled_pred\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Take mean over n_shuffles dim\u001b[39;00m\n\u001b[1;32m    119\u001b[0m shuffled_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(shuffled_preds, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (128) must match the existing size (10) at non-singleton dimension 0.  Target sizes: [128, 572, 5].  Tensor sizes: [10, 572, 5]"
     ]
    }
   ],
   "source": [
    "n_shuffles = 5\n",
    "window_size = 50\n",
    "\n",
    "# paths = [f\"../models/paper1_m{i}.pt\" for i in range(1, 11)]\n",
    "# model_labels = [\n",
    "#     \"negative_both\",\n",
    "#     \"negative_ac\",\n",
    "#     \"no_negative_both\",\n",
    "#     \"no_negative_ac\",\n",
    "#     \"sliding_window_categorical_both\",\n",
    "#     \"sliding_window_categorical_ac\",\n",
    "#     \"sliding_window_proba_both\",\n",
    "#     \"sliding_window_proba_ac\",\n",
    "#     \"sliding_window_proba_negative_both\",\n",
    "#     \"sliding_window_proba_negative_ac\",\n",
    "# ]\n",
    "# paths = [\"../models/mamba_prestim_jitter.pt\", \"../models/mamba_prestim_jitter_ac.pt\"]\n",
    "# model_labels = [\"prestim-jitter\", \"prestim-jitter-ac\"]\n",
    "paths = [\"../models/mamba_crop_jitter.pt\"]\n",
    "model_labels = [\"crop_jitter\"]\n",
    "model_kwargs = {\n",
    "    \"embed_dim\": 256,\n",
    "    \"n_channels\": 19,\n",
    "    \"n_classes\": len(labels),\n",
    "    \"n_layers\": 5,\n",
    "    \"global_pool\": False,\n",
    "    \"dropout\": 0.1,\n",
    "}\n",
    "corr_fun = spearman_corrcoef\n",
    "# TODO: Save all results\n",
    "# TODO: Check if hmp values are actually 0\n",
    "for path, label in zip(paths, model_labels):\n",
    "    if path is None:\n",
    "        continue\n",
    "\n",
    "    use_sliding_window = 'crop' in path\n",
    "    add_negative = 'negative' in path\n",
    "\n",
    "    testval_data = MultiXArrayProbaDataset(\n",
    "        data_paths,\n",
    "        participants_to_keep=splits[1] + splits[2],\n",
    "        normalization_fn=norm_fn,\n",
    "        norm_vars=norm_vars,\n",
    "        whole_epoch=whole_epoch,\n",
    "        labels=labels,\n",
    "        info_to_keep=info_to_keep,\n",
    "        subset_cond=subset_cond,\n",
    "        add_negative=add_negative,\n",
    "        skip_samples=skip_samples\n",
    "    )\n",
    "\n",
    "    print(f'Now testing model: {label}')\n",
    "    # Load model\n",
    "    model = MambaModel(**model_kwargs)\n",
    "    checkpoint = load_model(path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model = model.to(DEVICE)\n",
    "    model.pretraining = False\n",
    "    model.global_pool = False\n",
    "    model.eval()\n",
    "\n",
    "    # Create new loader so start is the same for each model\n",
    "    test_loader = DataLoader(\n",
    "        testval_data, batch_size=128, shuffle=False, num_workers=0, pin_memory=True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.set_grad_enabled(False)\n",
    "    corr_diffs = []\n",
    "    for batch in tqdm(test_loader):\n",
    "        hmp_probas = batch[1]\n",
    "        # Predict on data\n",
    "        data_batch = batch[0]\n",
    "        lengths = torch.sum(data_batch[:, :, 0] != MASKING_VALUE, dim=1)\n",
    "        if use_sliding_window:\n",
    "            all_window_preds = []\n",
    "            \n",
    "            for trial_idx in range(data_batch.shape[0]):\n",
    "                length = lengths[trial_idx].item()\n",
    "                if length < window_size:\n",
    "                    valid_data = data_batch[trial_idx, :length, :].unsqueeze(0)\n",
    "                    window_pred = model(valid_data.to(DEVICE))\n",
    "                    window_pred = torch.nn.Softmax(dim=2)(window_pred)\n",
    "                    all_window_preds.append(window_pred)\n",
    "                else:\n",
    "                    trial_preds_unfolded = torch.full((length, length, len(labels)), float('nan'))\n",
    "                    for start in range(0, length - window_size + 1):\n",
    "                        end = start + window_size\n",
    "                        window_data = data_batch[trial_idx, start:end, :].unsqueeze(0)\n",
    "                        window_pred = model(window_data.to(DEVICE))\n",
    "                        window_pred = torch.nn.Softmax(dim=2)(window_pred)\n",
    "                        trial_preds_unfolded[start, start:end, :] = window_pred\n",
    "                    trial_preds_unfolded = torch.nanmean(trial_preds_unfolded, dim=0)\n",
    "                    trial_preds_unfolded = torch.nn.functional.pad(trial_preds_unfolded, (0, 0, 0, data_batch.shape[1] - trial_preds_unfolded.shape[0]))\n",
    "                    all_window_preds.append(trial_preds_unfolded)\n",
    "                    model_pred = torch.stack(all_window_preds, dim=0)\n",
    "        else:\n",
    "            model_pred = model(batch[0].to(DEVICE))\n",
    "            model_pred = torch.nn.Softmax(dim=2)(model_pred)\n",
    "            pred_shape = model_pred.shape\n",
    "    \n",
    "        # Create (batch_size, n_shuffles, seq_len, n_classes) shape for storing shuffled predictions\n",
    "        shuffled_preds = torch.zeros((pred_shape[0], n_shuffles, pred_shape[1], pred_shape[2]))\n",
    "\n",
    "        for i in range(n_shuffles):\n",
    "            # Shuffle data up to rt_idx, predict again (n times?)\n",
    "            batch_data = batch[0].clone()\n",
    "\n",
    "            for trial in range(batch_data.shape[0]):\n",
    "                length = lengths[trial]\n",
    "                shuffle_section = batch_data[trial, :length]\n",
    "                shuffle_section = shuffle_section[torch.randperm(length)]\n",
    "                batch_data[trial, :length] = shuffle_section\n",
    "            \n",
    "            shuffled_pred = model(batch_data.to(DEVICE))\n",
    "            shuffled_pred = torch.nn.Softmax(dim=2)(shuffled_pred)\n",
    "            shuffled_preds[:, i, ...] = shuffled_pred\n",
    "        \n",
    "        # Take mean over n_shuffles dim\n",
    "        shuffled_preds = torch.mean(shuffled_preds, dim=1)\n",
    "\n",
    "        model_corrs = []\n",
    "        shuffled_corrs = []\n",
    "        for i in range(len(labels)):\n",
    "            model_corrs.append(corr_fun(model_pred[..., i], hmp_probas[..., i]))\n",
    "            shuffled_corrs.append(corr_fun(shuffled_preds[..., i], hmp_probas[..., i]))\n",
    "        corr_diffs.append(torch.Tensor(model_corrs) - torch.Tensor(shuffled_corrs))\n",
    "    results = torch.stack(corr_diffs).nanmean(dim=0)\n",
    "    print(f'{label} achieved: {results}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5652056932449341,\n",
       " 0.8104925155639648,\n",
       " 0.7749770283699036,\n",
       " 0.5627233982086182,\n",
       " 0.19457444548606873]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_corrs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
