{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find transformations with base model that maximize the difference between prediction and shuffled prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from hmpai.pytorch.models import *\n",
    "from hmpai.training import split_data_on_participants, split_participants, split_participants_into_folds\n",
    "from hmpai.pytorch.training import train, validate, calculate_class_weights, train_and_test, k_fold_cross_validate, test, calculate_global_class_weights\n",
    "from hmpai.pytorch.utilities import DEVICE, set_global_seed, get_summary_str, save_model, load_model\n",
    "from hmpai.pytorch.generators import SAT1Dataset, MultiXArrayDataset, MultiXArrayProbaDataset\n",
    "from hmpai.data import SAT1_STAGES_ACCURACY, SAT_CLASSES_ACCURACY\n",
    "from hmpai.visualization import plot_confusion_matrix\n",
    "from hmpai.pytorch.normalization import *\n",
    "from torchinfo import summary\n",
    "from hmpai.utilities import print_results, CHANNELS_2D, AR_SAT1_CHANNELS\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from hmpai.pytorch.transforms import *\n",
    "from collections import defaultdict\n",
    "from hmpai.pytorch.mamba import *\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))\n",
    "models = []\n",
    "N_FOLDS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_mamba():\n",
    "    embed_dim = 64\n",
    "    out_channels = 128\n",
    "    base_cnn = nn.Sequential(\n",
    "        nn.Conv1d(\n",
    "            in_channels=embed_dim,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=50,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    model_kwargs = {\n",
    "        \"embed_dim\": embed_dim,\n",
    "        \"mamba_dim\": out_channels,\n",
    "        \"n_channels\": 19,\n",
    "        \"n_classes\": len(labels),\n",
    "        \"n_mamba_layers\": 5,\n",
    "        \"cnn_module\": base_cnn,\n",
    "        \"dropout\": 0.1,\n",
    "    }\n",
    "    model = ConfigurableMamba(**model_kwargs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define transform configurations, separately for train and testval, probably dont want most transforms in case of testval but should still be configurable\n",
    "\n",
    "Can probably create dataset per fold, then set transform by doing `train_data.transform=transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First index = train set, second index is testval set\n",
    "# transforms = [(Compose([]), Compose([])),\n",
    "#               (Compose([]), Compose([])),\n",
    "#               (Compose([]), Compose([])),\n",
    "#               (Compose([]), Compose([])),\n",
    "#               (Compose([]), Compose([])),\n",
    "#               (Compose([]), Compose([])),\n",
    "#               (Compose([]), Compose([])),\n",
    "#               (Compose([]), Compose([])),\n",
    "#               (Compose([]), Compose([])),]\n",
    "# StartJitterTransform(62)\n",
    "# EndJitterTransform(63)\n",
    "# ReverseTimeTransform()\n",
    "# GaussianNoise()\n",
    "# TimeMaskTransform()\n",
    "# TimeDropoutTransform()\n",
    "# ChannelsDropout()\n",
    "#     (Compose([StartJitterTransform(62), EndJitterTransform(63)]), None),\n",
    "#     (Compose([StartJitterTransform(62), EndJitterTransform(63), ReverseTimeTransform()]), None),\n",
    "# First test if transforms by themselves make a difference, assume additive behaviour\n",
    "transforms = [\n",
    "    (None, None),\n",
    "    (Compose([StartJitterTransform(62)]), None),\n",
    "    # (Compose([EndJitterTransform(63)]), None),\n",
    "    # (Compose([ReverseTimeTransform()]), None),\n",
    "    # (Compose([GaussianNoise()]), None),\n",
    "    # (Compose([TimeMaskTransform()]), None),\n",
    "    # (Compose([TimeDropoutTransform()]), None),\n",
    "    # (Compose([ChannelsDropout()]), None),\n",
    "    # (Compose([ConcatenateTransform(0.5)]), None),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'StartJitterTransform'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms[1][0].transforms[0].__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['S17' 'S10' 'S15' 'S1' 'S18']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c4d44bfde8491a8ce48bac65b070f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, transform: None: EMD: tensor([-1.1785e-04, -1.0405e-04, -1.3804e-04, -2.0141e-05],\n",
      "       dtype=torch.float64), EMD_raw: torch.Size([5790, 4])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6064995109c44079f32a1169427ce5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, transform: Compose(\n",
      "    <hmpai.pytorch.transforms.StartJitterTransform object at 0x7f4929c87f10>\n",
      "): EMD: tensor([-0.0001, -0.0002, -0.0002, -0.0001], dtype=torch.float64), EMD_raw: torch.Size([5790, 4])\n",
      "Fold 2: test fold: ['S11' 'S13' 'S12' 'S16']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d005fe0a0154ede97c625248579e2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, transform: None: EMD: tensor([-4.7935e-05, -7.0328e-05, -2.3023e-04, -2.0602e-04],\n",
      "       dtype=torch.float64), EMD_raw: torch.Size([4435, 4])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbe855117f04133ae1c729ef63626d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, transform: Compose(\n",
      "    <hmpai.pytorch.transforms.StartJitterTransform object at 0x7f4929c87f10>\n",
      "): EMD: tensor([-2.4292e-04, -2.7995e-04, -3.8946e-05,  1.3507e-05],\n",
      "       dtype=torch.float64), EMD_raw: torch.Size([4435, 4])\n"
     ]
    }
   ],
   "source": [
    "from hmpai.pytorch.utilities import save_tensor\n",
    "\n",
    "\n",
    "data_path_1 = DATA_PATH / \"sat2/stage_data_proba_250hz_part1.nc\"\n",
    "data_path_2 = DATA_PATH / \"sat2/stage_data_proba_250hz_part2.nc\"\n",
    "# data_paths = [data_path_1, data_path_2]\n",
    "data_paths = [data_path_1] # TODO: Both paths\n",
    "\n",
    "logs_path = Path(\"../../logs/transformation_validation\")\n",
    "\n",
    "set_global_seed(42)\n",
    "folds = split_participants_into_folds(data_paths, N_FOLDS)\n",
    "\n",
    "results = defaultdict(list)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for i_fold in range(len(folds)):\n",
    "    train_folds = deepcopy(folds)\n",
    "    test_fold = train_folds.pop(i_fold)\n",
    "    train_fold = np.concatenate(train_folds, axis=0)\n",
    "    print(f\"Fold {i_fold + 1}: test fold: {test_fold}\")\n",
    "\n",
    "    labels = SAT_CLASSES_ACCURACY\n",
    "    whole_epoch = True\n",
    "    # Maybe 'accuracy'? probably not necessary\n",
    "    subset_cond = 'accuracy'\n",
    "    add_negative = True\n",
    "    norm_fn = norm_mad_zscore\n",
    "\n",
    "    train_data = MultiXArrayProbaDataset(\n",
    "        data_paths,\n",
    "        participants_to_keep=train_fold,\n",
    "        normalization_fn=norm_fn\n",
    "        whole_epoch=whole_epoch,\n",
    "        labels=labels,\n",
    "        subset_cond=subset_cond,\n",
    "        add_negative=add_negative,\n",
    "    )\n",
    "    norm_vars = get_norm_vars_from_global_statistics(train_data.statistics, norm_fn)\n",
    "    class_weights = train_data.statistics[\"class_weights\"]\n",
    "    testval_data = MultiXArrayProbaDataset(\n",
    "        data_paths,\n",
    "        participants_to_keep=test_fold,\n",
    "        normalization_fn=norm_fn,\n",
    "        norm_vars=norm_vars,\n",
    "        whole_epoch=whole_epoch,\n",
    "        labels=labels,\n",
    "        subset_cond=subset_cond,\n",
    "        add_negative=add_negative,\n",
    "    )\n",
    "\n",
    "    for i_t, (t_train, t_test) in enumerate(transforms):\n",
    "        # Set transforms\n",
    "        train_data.transform = t_train\n",
    "        testval_data.transform = t_test\n",
    "\n",
    "        model = base_mamba()\n",
    "        additional_name = 'None' if t_train is None else f\"transform-{t_train.transforms[0].__class__.__name__}_fold-{i_fold}\"\n",
    "        test_result = train_and_test(\n",
    "            model,\n",
    "            train_data,\n",
    "            testval_data,\n",
    "            testval_data,\n",
    "            logs_path=logs_path,\n",
    "            workers=0,\n",
    "            batch_size=64,\n",
    "            labels=labels,\n",
    "            lr=0.001, # 0.0001\n",
    "            use_class_weights=False,\n",
    "            class_weights=class_weights,\n",
    "            whole_epoch=whole_epoch,\n",
    "            epochs=1,\n",
    "            additional_name=additional_name,\n",
    "            do_test_shuffled=True\n",
    "        )\n",
    "        print(f\"Fold {i_fold + 1}, transform: {str(t_train)}: EMD: {test_result[0]['EMD']}, EMD_raw: {test_result[0]['EMD_raw'].shape}\")\n",
    "        for i, result in enumerate(test_result):\n",
    "            results[i_t].append(result)\n",
    "\n",
    "for i_t, (t_train, t_test) in enumerate(transforms):\n",
    "    if isinstance(type(results[i_t][0]), dict):\n",
    "        with open(logs_path / f\"results_{str(t_train)}.json\", \"w\") as f:\n",
    "            json.dump(results[i_t], f, indent=4)\n",
    "    else:\n",
    "        for i_fold, fold in enumerate(results[i_t]):\n",
    "            tensors = fold[\"EMD_raw\"]\n",
    "            name = 'None' if t_train is None else t_train.transforms[0].__class__.__name__\n",
    "            save_tensor(tensors, logs_path / f\"results_{name}_fold_{i_fold}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
