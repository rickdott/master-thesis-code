{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from hmpai.pytorch.models import *\n",
    "from hmpai.training import split_data_on_participants, split_participants, split_participants_into_folds\n",
    "from hmpai.pytorch.training import train, validate, calculate_class_weights, train_and_test, k_fold_cross_validate, test, calculate_global_class_weights\n",
    "from hmpai.pytorch.utilities import DEVICE, set_global_seed, get_summary_str, save_model, load_model\n",
    "from hmpai.pytorch.generators import SAT1Dataset, MultiXArrayDataset, MultiXArrayProbaDataset\n",
    "from hmpai.data import SAT1_STAGES_ACCURACY, SAT_CLASSES_ACCURACY\n",
    "from hmpai.visualization import plot_confusion_matrix\n",
    "from hmpai.pytorch.normalization import *\n",
    "from torchinfo import summary\n",
    "from hmpai.utilities import print_results, CHANNELS_2D, AR_SAT1_CHANNELS\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from hmpai.pytorch.transforms import *\n",
    "from collections import defaultdict\n",
    "from hmpai.pytorch.mamba import *\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))\n",
    "models = []\n",
    "N_FOLDS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_mamba():\n",
    "    embed_dim = 64\n",
    "    out_channels = 128\n",
    "    base_cnn = nn.Sequential(\n",
    "        nn.Conv1d(\n",
    "            in_channels=embed_dim,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=50,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    model_kwargs = {\n",
    "        \"embed_dim\": embed_dim,\n",
    "        \"mamba_dim\": out_channels,\n",
    "        \"n_channels\": 19,\n",
    "        \"n_classes\": len(labels),\n",
    "        \"n_mamba_layers\": 5,\n",
    "        \"cnn_module\": base_cnn,\n",
    "        \"dropout\": 0.1,\n",
    "    }\n",
    "    model = ConfigurableMamba(**model_kwargs)\n",
    "    return model\n",
    "models.append(base_mamba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_cnn():\n",
    "    embed_dim = 64\n",
    "    out_channels = 64\n",
    "    model_kwargs = {\n",
    "        \"embed_dim\": embed_dim,\n",
    "        \"mamba_dim\": out_channels,\n",
    "        \"n_channels\": 19,\n",
    "        \"n_classes\": len(labels),\n",
    "        \"n_mamba_layers\": 5,\n",
    "        \"cnn_module\": None,\n",
    "        \"dropout\": 0.1,\n",
    "    }\n",
    "    model = ConfigurableMamba(**model_kwargs)\n",
    "    return model\n",
    "models.append(no_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_cnn():\n",
    "    embed_dim = 64\n",
    "    out_channels = 128\n",
    "    base_cnn = nn.Sequential(\n",
    "        nn.Conv1d(\n",
    "            in_channels=embed_dim,\n",
    "            out_channels=96,\n",
    "            kernel_size=50,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(\n",
    "            in_channels=96,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=24,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    model_kwargs = {\n",
    "        \"embed_dim\": embed_dim,\n",
    "        \"mamba_dim\": out_channels,\n",
    "        \"n_channels\": 19,\n",
    "        \"n_classes\": len(labels),\n",
    "        \"n_mamba_layers\": 5,\n",
    "        \"cnn_module\": base_cnn,\n",
    "        \"dropout\": 0.1,\n",
    "    }\n",
    "    model = ConfigurableMamba(**model_kwargs)\n",
    "    return model\n",
    "models.append(two_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_cnn():\n",
    "    embed_dim = 64\n",
    "    out_channels = 128\n",
    "    base_cnn = nn.Sequential(\n",
    "        nn.Conv1d(\n",
    "            in_channels=embed_dim,\n",
    "            out_channels=85,\n",
    "            kernel_size=50,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(\n",
    "            in_channels=85,\n",
    "            out_channels=106,\n",
    "            kernel_size=24,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(\n",
    "            in_channels=106,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=12,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    model_kwargs = {\n",
    "        \"embed_dim\": embed_dim,\n",
    "        \"mamba_dim\": out_channels,\n",
    "        \"n_channels\": 19,\n",
    "        \"n_classes\": len(labels),\n",
    "        \"n_mamba_layers\": 5,\n",
    "        \"cnn_module\": base_cnn,\n",
    "        \"dropout\": 0.1,\n",
    "    }\n",
    "    model = ConfigurableMamba(**model_kwargs)\n",
    "    return model\n",
    "models.append(three_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twostream_cnn():\n",
    "    # TODO: Rethink whatever this is, I think putting features into channel/time dimension is not good, channels are of course a feature as well but idk\n",
    "    embed_dim = 64\n",
    "    out_channels = 128\n",
    "    space_conv = nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(1, 1),  # Convolution over the channel dimension (n_channels)\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "\n",
    "    time_conv = nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=(50, 1),\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "\n",
    "    model_kwargs = {\n",
    "        \"embed_dim\": embed_dim,\n",
    "        \"mamba_dim\": 2 * out_channels,\n",
    "        \"n_channels\": 19,\n",
    "        \"n_classes\": len(labels),\n",
    "        \"n_mamba_layers\": 5,\n",
    "        \"space_cnn_module\": space_conv,\n",
    "        \"time_cnn_module\": time_conv,\n",
    "        \"dropout\": 0.1,\n",
    "    }\n",
    "    model = ConfigurableMamba(**model_kwargs)\n",
    "    return model\n",
    "models.append(twostream_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: test fold: ['S1' 'S10' 'S18']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92fda1e9b7e4f4f87ce9989afc353b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ? batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "data_path_1 = DATA_PATH / \"sat2/stage_data_proba_250hz_part1.nc\"\n",
    "data_path_2 = DATA_PATH / \"sat2/stage_data_proba_250hz_part2.nc\"\n",
    "data_paths = [data_path_1, data_path_2]\n",
    "\n",
    "logs_path = Path(\"../../logs/architecture_validation\")\n",
    "\n",
    "set_global_seed(42)\n",
    "folds = split_participants_into_folds(data_paths, N_FOLDS)\n",
    "\n",
    "results = defaultdict(list)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for i_fold in range(len(folds)):\n",
    "    train_folds = deepcopy(folds)\n",
    "    test_fold = train_folds.pop(i_fold)\n",
    "    train_fold = np.concatenate(train_folds, axis=0)\n",
    "    print(f\"Fold {i_fold + 1}: test fold: {test_fold}\")\n",
    "\n",
    "    labels = SAT_CLASSES_ACCURACY\n",
    "    whole_epoch = True\n",
    "    # Maybe 'accuracy'? probably not necessary\n",
    "    subset_cond = None\n",
    "    add_negative = True\n",
    "    skip_samples = 0\n",
    "    norm_fn = norm_mad_zscore\n",
    "\n",
    "    train_data = MultiXArrayProbaDataset(\n",
    "        data_paths,\n",
    "        participants_to_keep=train_fold,\n",
    "        normalization_fn=norm_fn,\n",
    "        whole_epoch=whole_epoch,\n",
    "        labels=labels,\n",
    "        subset_cond=subset_cond,\n",
    "        add_negative=add_negative,\n",
    "    )\n",
    "    norm_vars = get_norm_vars_from_global_statistics(train_data.statistics, norm_fn)\n",
    "    class_weights = train_data.statistics[\"class_weights\"]\n",
    "    testval_data = MultiXArrayProbaDataset(\n",
    "        data_paths,\n",
    "        participants_to_keep=test_fold,\n",
    "        normalization_fn=norm_fn,\n",
    "        norm_vars=norm_vars,\n",
    "        whole_epoch=whole_epoch,\n",
    "        labels=labels,\n",
    "        subset_cond=subset_cond,\n",
    "        add_negative=add_negative,\n",
    "    )\n",
    "    for i_model, model_fn in enumerate(models):\n",
    "        model = model_fn()\n",
    "        test_result = train_and_test(\n",
    "            model,\n",
    "            train_data,\n",
    "            testval_data,\n",
    "            testval_data,\n",
    "            logs_path=logs_path,\n",
    "            workers=0,\n",
    "            batch_size=64,\n",
    "            labels=labels,\n",
    "            lr=0.0001,\n",
    "            use_class_weights=False,\n",
    "            class_weights=class_weights,\n",
    "            whole_epoch=whole_epoch,\n",
    "            epochs=20,\n",
    "            additional_name=f\"model_fn-{model_fn.__name__}_fold-{i_fold}\",\n",
    "        )\n",
    "        print(f\"Fold {i_fold + 1}, model: {model_fn.__name__}: KLDivLoss: {test_result[0]['KLDivLoss']}\")\n",
    "        for i, result in enumerate(test_result):\n",
    "            results[model_fn.__name__].append(result)\n",
    "for model_fn in models:\n",
    "    with open(logs_path / f\"results_{model_fn.__name__}.json\", \"w\") as f:\n",
    "        json.dump(results[model_fn.__name__], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.16.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "E0928 14:07:20.577132 140497037293120 _internal.py:97] Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/werkzeug/serving.py\", line 370, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/werkzeug/serving.py\", line 331, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 528, in __call__\n",
      "    return self._app(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 569, in wrapper\n",
      "    return wsgi_app(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/security_validator.py\", line 91, in __call__\n",
      "    return self._application(environ, start_response_proxy)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/path_prefix.py\", line 68, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/experiment_id.py\", line 73, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/empty_path_redirect.py\", line 43, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/client_feature_flags.py\", line 55, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/auth_context_middleware.py\", line 38, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 551, in _route_request\n",
      "    return self.exact_routes[clean_path](environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/werkzeug/wrappers/request.py\", line 190, in application\n",
      "    resp = f(*args[:-2] + (request,))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 121, in get_experiment_route\n",
      "    json_format.MessageToJson(\n",
      "TypeError: MessageToJson() got an unexpected keyword argument 'including_default_value_fields'\n",
      "E0928 14:07:22.110171 140497028900416 _internal.py:97] Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/werkzeug/serving.py\", line 370, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/werkzeug/serving.py\", line 331, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 528, in __call__\n",
      "    return self._app(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 569, in wrapper\n",
      "    return wsgi_app(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/security_validator.py\", line 91, in __call__\n",
      "    return self._application(environ, start_response_proxy)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/path_prefix.py\", line 68, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/experiment_id.py\", line 73, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/empty_path_redirect.py\", line 43, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/client_feature_flags.py\", line 55, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/auth_context_middleware.py\", line 38, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/backend/application.py\", line 551, in _route_request\n",
      "    return self.exact_routes[clean_path](environ, start_response)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/werkzeug/wrappers/request.py\", line 190, in application\n",
      "    resp = f(*args[:-2] + (request,))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 121, in get_experiment_route\n",
      "    json_format.MessageToJson(\n",
      "TypeError: MessageToJson() got an unexpected keyword argument 'including_default_value_fields'\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir ../../logs/architecture_validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
