{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from hmpai.pytorch.models import *\n",
    "from hmpai.training import split_data_on_participants, split_participants\n",
    "from hmpai.pytorch.training import train, validate, calculate_class_weights, train_and_test, k_fold_cross_validate, test, calculate_global_class_weights\n",
    "from hmpai.pytorch.utilities import DEVICE, set_global_seed, get_summary_str, save_model, load_model\n",
    "from hmpai.pytorch.generators import SAT1Dataset, MultiXArrayDataset, MultiXArrayProbaDataset\n",
    "from hmpai.data import SAT1_STAGES_ACCURACY, SAT_CLASSES_ACCURACY\n",
    "from hmpai.visualization import plot_confusion_matrix\n",
    "from hmpai.pytorch.normalization import *\n",
    "from torchinfo import summary\n",
    "from hmpai.utilities import print_results, CHANNELS_2D, AR_SAT1_CHANNELS\n",
    "from torch.utils.data import DataLoader\n",
    "from hmpai.pytorch.correlation import *\n",
    "# from braindecode.models.eegconformer import EEGConformer\n",
    "from mne.io import read_info\n",
    "import os\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))\n",
    "from hmpai.visualization import plot_predictions_on_epoch\n",
    "from hmpai.behaviour.sat2 import read_behavioural_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(42)\n",
    "data_path_1 = DATA_PATH / \"sat2/stage_data_proba_250hz_part1.nc\"\n",
    "data_path_2 = DATA_PATH / \"sat2/stage_data_proba_250hz_part2.nc\"\n",
    "data_paths = [data_path_1, data_path_2]\n",
    "# train_percentage=100 makes test and val 100 as well\n",
    "splits = split_participants(data_paths, train_percentage=60)\n",
    "labels = SAT_CLASSES_ACCURACY\n",
    "whole_epoch = True\n",
    "info_to_keep = ['event_name', 'participant', 'epochs']\n",
    "subset_cond = None # 'speed'|'accuracy'|None\n",
    "skip_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_fn = norm_mad_zscore\n",
    "statistics = {\n",
    "    \"global_min\": -0.00014557216,\n",
    "    \"global_max\": 0.00014740844,\n",
    "    \"global_mean\": -2.277374212336032e-18,\n",
    "    \"global_std\": 3.3968840765876904e-06,\n",
    "    \"global_median\": 3.4879516e-11,\n",
    "    \"mad_score\": 3.2237037e-06,\n",
    "    \"class_weights\": Tensor([0.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "}\n",
    "norm_vars = get_norm_vars_from_global_statistics(statistics, norm_fn)\n",
    "\n",
    "train_data = MultiXArrayProbaDataset(\n",
    "    data_paths,\n",
    "    participants_to_keep=splits[0],\n",
    "    normalization_fn=norm_fn,\n",
    "    whole_epoch=whole_epoch,\n",
    "    labels=labels,\n",
    "    info_to_keep=info_to_keep,\n",
    "    subset_cond=subset_cond,\n",
    "    statistics=statistics,\n",
    "    skip_samples=skip_samples,\n",
    ")\n",
    "class_weights = train_data.statistics[\"class_weights\"]\n",
    "test_data = MultiXArrayProbaDataset(\n",
    "    data_paths,\n",
    "    participants_to_keep=splits[1],\n",
    "    normalization_fn=norm_fn,\n",
    "    norm_vars=norm_vars,\n",
    "    whole_epoch=whole_epoch,\n",
    "    labels=labels,\n",
    "    info_to_keep=info_to_keep,\n",
    "    subset_cond=subset_cond,\n",
    "    skip_samples=skip_samples,\n",
    ")\n",
    "val_data = MultiXArrayProbaDataset(\n",
    "    data_paths,\n",
    "    participants_to_keep=splits[2],\n",
    "    normalization_fn=norm_fn,\n",
    "    norm_vars=norm_vars,\n",
    "    whole_epoch=whole_epoch,\n",
    "    labels=labels,\n",
    "    info_to_keep=info_to_keep,\n",
    "    subset_cond=subset_cond,\n",
    "    skip_samples=skip_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviour_sat2 = read_behavioural_info(DATA_PATH / \"sat2/behavioural/df_full.csv\")\n",
    "test_loader_sat2 = DataLoader(\n",
    "    test_data, batch_size=128, shuffle=True, num_workers=0, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_path = Path(\"../../models/mamba_conv.pt\")\n",
    "checkpoint = load_model(chk_path)\n",
    "\n",
    "model_kwargs = {\n",
    "    \"embed_dim\": 128,\n",
    "    \"n_channels\": 19,\n",
    "    \"n_classes\": len(labels),\n",
    "    \"n_layers\": 5,\n",
    "    \"global_pool\": False,\n",
    "    \"dropout\": 0.1,\n",
    "}\n",
    "model = MambaModel(**model_kwargs)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "model.pretraining = False\n",
    "model.global_pool = False\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader_sat2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m n_shuffles \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest_loader_sat2\u001b[49m:\n\u001b[1;32m      8\u001b[0m     info \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(batch[\u001b[38;5;241m0\u001b[39m][:, :, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m MASKING_VALUE, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader_sat2' is not defined"
     ]
    }
   ],
   "source": [
    "# SAT2\n",
    "window_size = 0\n",
    "amount_of_graphs = 5\n",
    "counter = 0\n",
    "n_shuffles = 5\n",
    "\n",
    "for batch in test_loader_sat2:\n",
    "    info = batch[2][0]\n",
    "    lengths = torch.sum(batch[0][:, :, 0] != MASKING_VALUE, dim=1)\n",
    "    for epoch, true, participant, trial, length in zip(batch[0], batch[1], info['participant'], info['epochs'], lengths):\n",
    "        plot_predictions_on_epoch(\n",
    "            epoch,\n",
    "            true,\n",
    "            SAT_CLASSES_ACCURACY,\n",
    "            window_size,\n",
    "            model,\n",
    "            smoothing=False,\n",
    "            sequence=True,\n",
    "            random_perm=True,\n",
    "        )\n",
    "        epoch = epoch.unsqueeze(0).to(DEVICE)\n",
    "        pred = model(epoch)\n",
    "        # shuffled_pred_log = torch.zeros_like(pred)\n",
    "        shuffled_pred = torch.zeros_like(pred)\n",
    "\n",
    "        for _ in range(n_shuffles):\n",
    "            epoch[0, :length] = epoch[0, torch.randperm(length)]\n",
    "            single_shuffled_pred = model(epoch)\n",
    "            # shuffled_pred_log += torch.nn.LogSoftmax(dim=2)(model(epoch))\n",
    "            shuffled_pred += torch.nn.Softmax(dim=2)(model(epoch))\n",
    "        # shuffled_pred_log /= n_shuffles\n",
    "        shuffled_pred /= n_shuffles\n",
    "\n",
    "        true = true[:pred.shape[1]]\n",
    "        true = true + 1e-8\n",
    "        true = true / true.sum(dim=-1, keepdim=True)\n",
    "        true_kldiv = kldiv(pred, true)\n",
    "        shuffled_kldiv = kldiv(shuffled_pred, true)\n",
    "\n",
    "        print(f'KLDivLoss - True: {true_kldiv}, Shuffled: {shuffled_kldiv}')\n",
    "        break\n",
    "    break\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
